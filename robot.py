import cv2
import torch
import torch.nn.functional as F
import time
import numpy as np
from new_model import TrafficSignMobileNet
from jetbotmini import Robot

# í´ë˜ìŠ¤ ì´ë¦„ ì •ì˜
class_names = ['green_light', 'left_sign', 'red_light', 'right_sign', 'stop_sign']

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cpu")
print(f"Using device: {device}")

# ëª¨ë¸ ë¡œë”©
model = TrafficSignMobileNet(num_classes=len(class_names))
model.load_state_dict(torch.load("traffic_sign_mobilenet.pth", map_location=device))
model.to(device)
model.eval()

# ë¡œë´‡ ì´ˆê¸°í™”
robot = Robot()
robot.set_motors(0.0, 0.0)

# ì˜ìƒ ì „ì²˜ë¦¬
def preprocess_with_cv2(frame):
    resized = cv2.resize(frame, (224, 224))
    rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)
    normalized = rgb.astype(np.float32) / 255.0
    tensor = torch.from_numpy(normalized).permute(2, 0, 1)
    tensor = (tensor - 0.5) / 0.5
    return tensor.unsqueeze(0).to(device)

# ì¹´ë©”ë¼ íŒŒì´í”„ë¼ì¸
def gstreamer_pipeline(capture_width=640, capture_height=480,
                       display_width=640, display_height=480,
                       framerate=5, flip_method=0):
    return (
        f"nvarguscamerasrc ! video/x-raw(memory:NVMM), width=(int){capture_width}, height=(int){capture_height}, "
        f"format=(string)NV12, framerate=(fraction){framerate}/1 ! nvvidconv flip-method={flip_method} ! "
        f"video/x-raw, width=(int){display_width}, height=(int){display_height}, format=(string)BGRx ! "
        f"videoconvert ! video/x-raw, format=(string)BGR ! appsink"
    )

# ì¹´ë©”ë¼ ì‹œì‘
cap = cv2.VideoCapture(gstreamer_pipeline(), cv2.CAP_GSTREAMER)
if not cap.isOpened():
    print("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

# ë³€ìˆ˜ ì´ˆê¸°í™”
last_inference_time = 0
last_display_time = 0
last_label_time = 0
label_cooldown = 5.0  # í‘œì§€íŒ ë°˜ì‘ ì¿¨ë‹¤ìš´ (ì´ˆ)

detected_label = None
detected_confidence = 0.0

is_driving = False
is_stopping = False

current_speed = 0.0
target_speed = 0.0
max_speed = 0.4
accel_time = 2.0
accel_step = 0.05
accel_interval = accel_time * accel_step / max_speed

decel_time = 2.0
decel_step = accel_step
decel_interval = accel_interval

last_accel_time = 0
last_decel_time = 0

detection_pause_until = None

# ì˜¤ë¥¸ìª½ ë°”í€´ê°€ ë” ë¹ ë¥¸ ê²½ìš° â†’ ì†ë„ ì¤„ì´ê¸°
motor_bias = -0.03

inference_interval = 0.2
display_interval = 0.1

while True:
    ret, frame = cap.read()
    if not ret:
        print("í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        break

    now = time.time()

    # === ì¶”ë¡  ===
    if not is_stopping and (detection_pause_until is None or now >= detection_pause_until):
        if now - last_inference_time > inference_interval:
            input_tensor = preprocess_with_cv2(frame)
            with torch.no_grad():
                output = model(input_tensor)
                probs = F.softmax(output, dim=1)
                confidence, pred = torch.max(probs, 1)

            confidence_val = confidence.item()
            pred_idx = pred.item()
            last_inference_time = now

            # === ì¿¨ë‹¤ìš´ ì´í›„ì—ë§Œ ë°˜ì‘ ===
            if confidence_val > 0.3 and (now - last_label_time > label_cooldown):
                detected_label = class_names[pred_idx]
                detected_confidence = confidence_val
                last_label_time = now
            else:
                detected_label = None
                detected_confidence = 0.0

            # ì´ˆë¡ë¶ˆ ê°ì§€ í›„ ì£¼í–‰ ì‹œì‘
            if detected_label == "green_light" and not is_driving:
                print("âœ… ì´ˆë¡ë¶ˆ ê°ì§€ â†’ 10ì´ˆ íƒì§€ ì¤‘ì§€ & 2ì´ˆ ê°€ì†")
                is_driving = True
                target_speed = max_speed
                last_accel_time = now
                detection_pause_until = now + 10  # 10ì´ˆ ë™ì•ˆ íƒì§€ ì¤‘ì§€

            # ë©ˆì¶¤í‘œì§€ ê°ì§€ ì‹œ ê°ì†
            elif detected_label == "stop_sign" and is_driving and not is_stopping:
                print("ğŸ›‘ ë©ˆì¶¤í‘œì§€ ê°ì§€ â†’ ê°ì† í›„ ì¢…ë£Œ")
                is_stopping = True
                last_decel_time = now
                detection_pause_until = None

    # === ê°€ì† ===
    if is_driving and not is_stopping:
        if current_speed < target_speed and now - last_accel_time > accel_interval:
            current_speed += accel_step
            current_speed = min(current_speed, target_speed)
            last_accel_time = now
            print(f"[ê°€ì†] ì†ë„: {current_speed:.2f}")
        robot.set_motors(current_speed, current_speed + motor_bias)

    # === ê°ì† ===
    if is_stopping:
        if current_speed > 0 and now - last_decel_time > decel_interval:
            current_speed -= decel_step
            current_speed = max(current_speed, 0.0)
            last_decel_time = now
            print(f"[ê°ì†] ì†ë„: {current_speed:.2f}")
        robot.set_motors(current_speed, current_speed + motor_bias)
        if current_speed == 0.0:
            print("ğŸ›‘ ì™„ì „ ì •ì§€ â†’ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
            break

    # === ì˜ìƒ ì¶œë ¥ ===
    if detected_label:
        text = f"{detected_label} ({detected_confidence * 100:.1f}%)"
        cv2.putText(frame, text, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
        cv2.rectangle(frame, (5, 5), (320, 60), (0, 255, 0), 2)

    cv2.imshow("Traffic Sign Detection", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ì •ì§€ í›„ ì¢…ë£Œ
robot.set_motors(0.0, 0.0)
cap.release()
cv2.destroyAllWindows()
